{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "9caf8b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "file_path = 'tweet_data/train.txt'\n",
    "\n",
    "def read_data(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        return file.read()\n",
    "\n",
    "def process_data(data):\n",
    "    blocks = data.strip().split(\"<START>\")[1:]\n",
    "    processed_blocks = []\n",
    "\n",
    "    for block in blocks:\n",
    "        lines = block.strip().split(\"\\n\")[1:-1]  \n",
    "        words = []\n",
    "        special_word = None\n",
    "        special_word_count = 0  \n",
    "        for line in lines:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) == 2 and parts[1] == \"O\":\n",
    "                words.append(parts[0])\n",
    "            elif len(parts) == 2 and parts[1].startswith(\":\") and parts[1].endswith(\":\"):\n",
    "                if not special_word:\n",
    "                    special_word = parts[1]  \n",
    "                    special_word_count += 1\n",
    "                elif special_word == parts[1]:  \n",
    "                    special_word_count += 1\n",
    "\n",
    "        if special_word_count <= 1:  \n",
    "            sentence = \" \".join(words)\n",
    "            processed_blocks.append((sentence, special_word))\n",
    "\n",
    "    return processed_blocks\n",
    "\n",
    "def create_dataframe(processed_data):\n",
    "    return pd.DataFrame(processed_data, columns=[\"Sentence\", \"First Special Word\"])\n",
    "\n",
    "data = read_data(file_path)\n",
    "processed_data = process_data(data)\n",
    "df = create_dataframe(processed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "061c6e77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>First Special Word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CeeC is going to be another Tboss What is 45 m...</td>\n",
       "      <td>:face_with_tears_of_joy:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This gif kills me Death is literally gushing t...</td>\n",
       "      <td>:weary_face:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LOVE TEST Raw Real</td>\n",
       "      <td>:purple_heart:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i swear we dont gotta look it finds</td>\n",
       "      <td>:face_with_tears_of_joy:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We would like to wish everyone a very Happy Ne...</td>\n",
       "      <td>:party_popper:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6159366</th>\n",
       "      <td>Follow everyone who likes this</td>\n",
       "      <td>:white_heavy_check_mark:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6159367</th>\n",
       "      <td>we LOVE a simlish</td>\n",
       "      <td>:rolling_on_the_floor_laughing:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6159368</th>\n",
       "      <td>No fan base is more dedicated than the 1D fan ...</td>\n",
       "      <td>:yellow_heart:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6159369</th>\n",
       "      <td>Im surprised yall havent purposely hit me yet</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6159370</th>\n",
       "      <td>fav de x9</td>\n",
       "      <td>:heart_suit:</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6159371 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Sentence  \\\n",
       "0        CeeC is going to be another Tboss What is 45 m...   \n",
       "1        This gif kills me Death is literally gushing t...   \n",
       "2                                       LOVE TEST Raw Real   \n",
       "3                      i swear we dont gotta look it finds   \n",
       "4        We would like to wish everyone a very Happy Ne...   \n",
       "...                                                    ...   \n",
       "6159366                     Follow everyone who likes this   \n",
       "6159367                                  we LOVE a simlish   \n",
       "6159368  No fan base is more dedicated than the 1D fan ...   \n",
       "6159369      Im surprised yall havent purposely hit me yet   \n",
       "6159370                                          fav de x9   \n",
       "\n",
       "                      First Special Word  \n",
       "0               :face_with_tears_of_joy:  \n",
       "1                           :weary_face:  \n",
       "2                         :purple_heart:  \n",
       "3               :face_with_tears_of_joy:  \n",
       "4                         :party_popper:  \n",
       "...                                  ...  \n",
       "6159366         :white_heavy_check_mark:  \n",
       "6159367  :rolling_on_the_floor_laughing:  \n",
       "6159368                   :yellow_heart:  \n",
       "6159369                             None  \n",
       "6159370                     :heart_suit:  \n",
       "\n",
       "[6159371 rows x 2 columns]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "0a6edea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "First Special Word\n",
       ":face_with_tears_of_joy:            1140886\n",
       ":loudly_crying_face:                 455284\n",
       ":red_heart:                          406399\n",
       ":smiling_face_with_heart-eyes:       321974\n",
       ":fire:                               279014\n",
       ":weary_face:                         160562\n",
       ":folded_hands:                       152782\n",
       ":person_shrugging:                   140072\n",
       ":two_hearts:                         132720\n",
       ":thinking_face:                      122735\n",
       ":smiling_face_with_smiling_eyes:     122696\n",
       ":sparkles:                           119607\n",
       ":person_facepalming:                 106278\n",
       ":hundred_points:                     101273\n",
       ":rolling_on_the_floor_laughing:      100979\n",
       ":raising_hands:                      100211\n",
       ":eyes:                                99903\n",
       ":face_with_rolling_eyes:              98064\n",
       ":party_popper:                        84268\n",
       ":skull:                               84019\n",
       ":backhand_index_pointing_right:       76931\n",
       ":clapping_hands:                      76298\n",
       ":purple_heart:                        75008\n",
       ":face_blowing_a_kiss:                 74025\n",
       ":thumbs_up:                           73385\n",
       ":flexed_biceps:                       71115\n",
       ":winking_face:                        70610\n",
       ":blue_heart:                          69610\n",
       ":sparkling_heart:                     66254\n",
       ":smiling_face_with_sunglasses:        65056\n",
       ":female_sign:                         61487\n",
       ":beaming_face_with_smiling_eyes:      61338\n",
       ":OK_hand:                             59183\n",
       ":police_car_light:                    57160\n",
       ":heart_suit:                          57121\n",
       ":double_exclamation_mark:             55227\n",
       ":crying_face:                         54227\n",
       ":flushed_face:                        52626\n",
       ":smiling_face:                        52241\n",
       ":backhand_index_pointing_down:        49160\n",
       ":yellow_heart:                        45499\n",
       ":collision:                           44832\n",
       ":male_sign:                           42841\n",
       ":speaking_head:                       42008\n",
       ":right_arrow:                         39787\n",
       ":trophy:                              37686\n",
       ":glowing_star:                        35956\n",
       ":white_heavy_check_mark:              18718\n",
       ":heavy_check_mark:                    15389\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['First Special Word'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "bc8b2072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentence              So True A ️ True BidyMind amp Soul Blessings 2...\n",
       "First Special Word                                         :heart_suit:\n",
       "Name: 223424, dtype: object"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[223424]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "d147eec6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>emoji</th>\n",
       "      <th>unicode</th>\n",
       "      <th>name</th>\n",
       "      <th>Apple</th>\n",
       "      <th>Google</th>\n",
       "      <th>Facebook</th>\n",
       "      <th>Windows</th>\n",
       "      <th>Twitter</th>\n",
       "      <th>JoyPixels</th>\n",
       "      <th>Samsung</th>\n",
       "      <th>Gmail</th>\n",
       "      <th>SoftBank</th>\n",
       "      <th>DoCoMo</th>\n",
       "      <th>KDDI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>😀</td>\n",
       "      <td>U+1F600</td>\n",
       "      <td>grinning face</td>\n",
       "      <td>data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...</td>\n",
       "      <td>data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...</td>\n",
       "      <td>data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...</td>\n",
       "      <td>data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...</td>\n",
       "      <td>data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...</td>\n",
       "      <td>data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...</td>\n",
       "      <td>data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...</td>\n",
       "      <td>data:image/png;base64,R0lGODlhDAAPAKIFAJh3AP/z...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>😃</td>\n",
       "      <td>U+1F603</td>\n",
       "      <td>grinning face with big eyes</td>\n",
       "      <td>data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...</td>\n",
       "      <td>data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...</td>\n",
       "      <td>data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...</td>\n",
       "      <td>data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...</td>\n",
       "      <td>data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...</td>\n",
       "      <td>data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...</td>\n",
       "      <td>data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...</td>\n",
       "      <td>data:image/png;base64,R0lGODlhDAAMAKIFAF5LAP/z...</td>\n",
       "      <td>data:image/png;base64,R0lGODlhDwAPAKIAAP///wAA...</td>\n",
       "      <td>data:image/png;base64,R0lGODlhDAAMAIABAMxm////...</td>\n",
       "      <td>data:image/png;base64,R0lGODlhDgAPALMJAP//mf/M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>😄</td>\n",
       "      <td>U+1F604</td>\n",
       "      <td>grinning face with smiling eyes</td>\n",
       "      <td>data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...</td>\n",
       "      <td>data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...</td>\n",
       "      <td>data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...</td>\n",
       "      <td>data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...</td>\n",
       "      <td>data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...</td>\n",
       "      <td>data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...</td>\n",
       "      <td>data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...</td>\n",
       "      <td>data:image/png;base64,R0lGODlhDAAMAKIGAF5LAJh3...</td>\n",
       "      <td>data:image/png;base64,R0lGODlhDwAPAHcAMSH+GlNv...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>😁</td>\n",
       "      <td>U+1F601</td>\n",
       "      <td>beaming face with smiling eyes</td>\n",
       "      <td>data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...</td>\n",
       "      <td>data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...</td>\n",
       "      <td>data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...</td>\n",
       "      <td>data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...</td>\n",
       "      <td>data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...</td>\n",
       "      <td>data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...</td>\n",
       "      <td>data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...</td>\n",
       "      <td>data:image/png;base64,R0lGODlhDAAMAKIGAIoAAf/v...</td>\n",
       "      <td>data:image/png;base64,R0lGODlhDwAPAHcAMSH+GlNv...</td>\n",
       "      <td>data:image/png;base64,R0lGODlhDAAMAIABAP+ZAP//...</td>\n",
       "      <td>data:image/png;base64,R0lGODlhDgAPALMIAJmZmf//...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>😆</td>\n",
       "      <td>U+1F606</td>\n",
       "      <td>grinning squinting face</td>\n",
       "      <td>data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...</td>\n",
       "      <td>data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...</td>\n",
       "      <td>data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...</td>\n",
       "      <td>data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...</td>\n",
       "      <td>data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...</td>\n",
       "      <td>data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...</td>\n",
       "      <td>data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...</td>\n",
       "      <td>data:image/png;base64,R0lGODlhEAAMAKIFAF5LAP/z...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>data:image/png;base64,R0lGODlhDAAMAIABAMxm////...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   # emoji  unicode                             name  \\\n",
       "0  1     😀  U+1F600                    grinning face   \n",
       "1  2     😃  U+1F603      grinning face with big eyes   \n",
       "2  3     😄  U+1F604  grinning face with smiling eyes   \n",
       "3  4     😁  U+1F601   beaming face with smiling eyes   \n",
       "4  5     😆  U+1F606          grinning squinting face   \n",
       "\n",
       "                                               Apple  \\\n",
       "0  data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...   \n",
       "1  data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...   \n",
       "2  data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...   \n",
       "3  data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...   \n",
       "4  data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...   \n",
       "\n",
       "                                              Google  \\\n",
       "0  data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...   \n",
       "1  data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...   \n",
       "2  data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...   \n",
       "3  data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...   \n",
       "4  data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...   \n",
       "\n",
       "                                            Facebook  \\\n",
       "0  data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...   \n",
       "1  data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...   \n",
       "2  data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...   \n",
       "3  data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...   \n",
       "4  data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...   \n",
       "\n",
       "                                             Windows  \\\n",
       "0  data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...   \n",
       "1  data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...   \n",
       "2  data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...   \n",
       "3  data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...   \n",
       "4  data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...   \n",
       "\n",
       "                                             Twitter  \\\n",
       "0  data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...   \n",
       "1  data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...   \n",
       "2  data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...   \n",
       "3  data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...   \n",
       "4  data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...   \n",
       "\n",
       "                                           JoyPixels  \\\n",
       "0  data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...   \n",
       "1  data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...   \n",
       "2  data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...   \n",
       "3  data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...   \n",
       "4  data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...   \n",
       "\n",
       "                                             Samsung  \\\n",
       "0  data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...   \n",
       "1  data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...   \n",
       "2  data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...   \n",
       "3  data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...   \n",
       "4  data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...   \n",
       "\n",
       "                                               Gmail  \\\n",
       "0  data:image/png;base64,R0lGODlhDAAPAKIFAJh3AP/z...   \n",
       "1  data:image/png;base64,R0lGODlhDAAMAKIFAF5LAP/z...   \n",
       "2  data:image/png;base64,R0lGODlhDAAMAKIGAF5LAJh3...   \n",
       "3  data:image/png;base64,R0lGODlhDAAMAKIGAIoAAf/v...   \n",
       "4  data:image/png;base64,R0lGODlhEAAMAKIFAF5LAP/z...   \n",
       "\n",
       "                                            SoftBank  \\\n",
       "0                                                NaN   \n",
       "1  data:image/png;base64,R0lGODlhDwAPAKIAAP///wAA...   \n",
       "2  data:image/png;base64,R0lGODlhDwAPAHcAMSH+GlNv...   \n",
       "3  data:image/png;base64,R0lGODlhDwAPAHcAMSH+GlNv...   \n",
       "4                                                NaN   \n",
       "\n",
       "                                              DoCoMo  \\\n",
       "0                                                NaN   \n",
       "1  data:image/png;base64,R0lGODlhDAAMAIABAMxm////...   \n",
       "2                                                NaN   \n",
       "3  data:image/png;base64,R0lGODlhDAAMAIABAP+ZAP//...   \n",
       "4  data:image/png;base64,R0lGODlhDAAMAIABAMxm////...   \n",
       "\n",
       "                                                KDDI  \n",
       "0                                                NaN  \n",
       "1  data:image/png;base64,R0lGODlhDgAPALMJAP//mf/M...  \n",
       "2                                                NaN  \n",
       "3  data:image/png;base64,R0lGODlhDgAPALMIAJmZmf//...  \n",
       "4                                                NaN  "
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emoji = pd.read_csv('emojipedia/full_emoji.csv')\n",
    "emoji.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "53848d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 line\n",
      "0   I fall asleep every movie night me and my boyf...\n",
      "1                        i’m coming for it all... 💰\\n\n",
      "2       I’ll take a mixer. K thanks 😘😂 just kidding\\n\n",
      "3   Hearing this new and thinking to myself: \" 🤔 h...\n",
      "4   LeBron starts play with the short pull-up and ...\n",
      "5       I’ll take a mixer. K thanks 😘😂 just kidding\\n\n",
      "6   Magnus wasn't sure if that french toast was go...\n",
      "7   Brand New Look of StylishStar from  😎😎😎👌👌👌 Aud...\n",
      "8   Now you can celebrate tiny victories in the ki...\n",
      "9        Have a happy Wednesday my dear friends🌺🍃🌺🌱\\n\n",
      "10                    Tiffany liked &amp; comment😆💗💗💗\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>line</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I fall asleep every movie night me and my boyf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i’m coming for it all... 💰\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I’ll take a mixer. K thanks 😘😂 just kidding\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hearing this new and thinking to myself: \" 🤔 h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LeBron starts play with the short pull-up and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I’ll take a mixer. K thanks 😘😂 just kidding\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Magnus wasn't sure if that french toast was go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Brand New Look of StylishStar from  😎😎😎👌👌👌 Aud...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Now you can celebrate tiny victories in the ki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Have a happy Wednesday my dear friends🌺🍃🌺🌱\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Tiffany liked &amp;amp; comment😆💗💗💗</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 line\n",
       "0   I fall asleep every movie night me and my boyf...\n",
       "1                        i’m coming for it all... 💰\\n\n",
       "2       I’ll take a mixer. K thanks 😘😂 just kidding\\n\n",
       "3   Hearing this new and thinking to myself: \" 🤔 h...\n",
       "4   LeBron starts play with the short pull-up and ...\n",
       "5       I’ll take a mixer. K thanks 😘😂 just kidding\\n\n",
       "6   Magnus wasn't sure if that french toast was go...\n",
       "7   Brand New Look of StylishStar from  😎😎😎👌👌👌 Aud...\n",
       "8   Now you can celebrate tiny victories in the ki...\n",
       "9        Have a happy Wednesday my dear friends🌺🍃🌺🌱\\n\n",
       "10                    Tiffany liked &amp; comment😆💗💗💗"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"tweet_data/testing.txt\") as myfile:\n",
    "    mydata = (line for line in myfile)\n",
    "    testing = pd.DataFrame(mydata, columns=['line'])\n",
    "    print(testing)\n",
    "\n",
    "testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "c7edb158",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import pad_sequences\n",
    "\n",
    "# Tokenize text\n",
    "tokenizer = Tokenizer(num_words=5000, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(df['Sentence'])\n",
    "sequences = tokenizer.texts_to_sequences(df['Sentence'])\n",
    "\n",
    "# Pad sequences\n",
    "max_length = max(len(x) for x in sequences)\n",
    "X = pad_sequences(sequences, maxlen=max_length, padding='post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "e60740d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Encode emojis\n",
    "label_encoder = LabelEncoder()\n",
    "emoji_labels = label_encoder.fit_transform(df['First Special Word'])\n",
    "Y = to_categorical(emoji_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "32da5f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "1c910f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 119, 64)           320000    \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 119, 64)           33024     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 119, 64)           0         \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 50)                1650      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 389,778\n",
      "Trainable params: 389,778\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-17 22:23:57.558782: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-04-17 22:23:57.560226: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-04-17 22:23:57.561141: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-04-17 22:23:57.664708: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-04-17 22:23:57.665323: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-04-17 22:23:57.665818: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "\n",
    "# Build the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=5000, output_dim=64, input_length=max_length))\n",
    "model.add(LSTM(64, return_sequences=True))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(Y.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "cec581e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-17 22:24:43.186712: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-04-17 22:24:43.187504: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-04-17 22:24:43.188190: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-04-17 22:24:43.282216: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-04-17 22:24:43.282839: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-04-17 22:24:43.283380: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-04-17 22:24:43.667663: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-04-17 22:24:43.668406: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-04-17 22:24:43.668901: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-04-17 22:24:45.492631: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-04-17 22:24:45.493179: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-04-17 22:24:45.493881: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3269/153985 [..............................] - ETA: 2:47:45 - loss: 3.4389 - accuracy: 0.1833"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[173], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, validation_data\u001b[38;5;241m=\u001b[39m(X_test, y_test), batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/engine/training.py:1685\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1677\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1678\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1679\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1682\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1683\u001b[0m ):\n\u001b[1;32m   1684\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1685\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[1;32m   1686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1687\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    891\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    893\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 894\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    896\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    897\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:926\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    923\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    924\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    925\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 926\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_no_variable_creation_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    927\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    928\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    929\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    930\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    141\u001b[0m   (concrete_function,\n\u001b[1;32m    142\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m concrete_function\u001b[38;5;241m.\u001b[39m_call_flat(\n\u001b[1;32m    144\u001b[0m     filtered_flat_args, captured_inputs\u001b[38;5;241m=\u001b[39mconcrete_function\u001b[38;5;241m.\u001b[39mcaptured_inputs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1753\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1754\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1755\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1756\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1757\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function\u001b[38;5;241m.\u001b[39mcall(\n\u001b[1;32m   1758\u001b[0m       ctx, args, cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager))\n\u001b[1;32m   1759\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1760\u001b[0m     args,\n\u001b[1;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1762\u001b[0m     executing_eagerly)\n\u001b[1;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    380\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 381\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[1;32m    382\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    383\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m    384\u001b[0m         inputs\u001b[38;5;241m=\u001b[39margs,\n\u001b[1;32m    385\u001b[0m         attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[1;32m    386\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx)\n\u001b[1;32m    387\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    388\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    389\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    390\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    393\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    394\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test), batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "359a2cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 17ms/step\n",
      "[':smiling_face_with_heart-eyes:' ':loudly_crying_face:' ':two_hearts:'\n",
      " ':red_heart:']\n"
     ]
    }
   ],
   "source": [
    "def predict_emoji(text):\n",
    "    seq = tokenizer.texts_to_sequences([text])\n",
    "    padded = pad_sequences(seq, maxlen=max_length, padding='post')\n",
    "    pred = model.predict(padded)\n",
    "    return label_encoder.inverse_transform(pred.argsort(axis=1)[:,-4:][0])[::-1]  # Top 3 predictions\n",
    "\n",
    "# Example\n",
    "print(predict_emoji(\"I'm so happy!\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_emoji_format(emoji_str):\n",
    "    # Remove the colons at the start and end\n",
    "    cleaned_str = emoji_str.strip(':')\n",
    "    # Replace underscores with spaces\n",
    "    result_str = cleaned_str.replace('_', ' ')\n",
    "    return result_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "a1afc2a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 17ms/step\n",
      "Ill be lying if I said I wasnt missing you,Love you Brah 😂\n",
      "Ill be lying if I said I wasnt missing you,Love you Brah 😭\n",
      "Ill be lying if I said I wasnt missing you,Love you Brah 😩\n",
      "Ill be lying if I said I wasnt missing you,Love you Brah 💯\n"
     ]
    }
   ],
   "source": [
    "test_sentence = \"Ill be lying if I said I wasnt missing you,Love you Brah\"\n",
    "\n",
    "preds = predict_emoji(test_sentence)\n",
    "if len(preds) >= 0:\n",
    "    for i in range(len(preds)):\n",
    "        print(test_sentence, emoji[emoji['name'] == convert_emoji_format(preds[i])]['emoji'].item())\n",
    "else:\n",
    "    print('No predictions. :(')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "5ec003c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'6    🤣\\nName: emoji, dtype: object'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emoji[emoji['name'] == 'rolling on the floor laughing']['emoji']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "153704eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9624/9624 [==============================] - 95s 10ms/step - loss: 2.5186 - accuracy: 0.3490\n",
      "Test Accuracy: 0.3490217626094818\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
